{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fdc0b57",
   "metadata": {},
   "source": [
    "# Handwritten digit recognition using cnn (mnist dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1779fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56c0bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d37d896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79b08759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9504b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02af9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train), (X_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1816195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d5caf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6f140fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0eb9448b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcd4bd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b07e1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since cnn takes inputs as image, so reshaping the training as well as test input datasets such that each data would be of shape (28,28,1)\n",
    "X_train=X_train.reshape(X_train.shape[0],28,28,1).astype('float32')\n",
    "X_test=X_test.reshape(X_test.shape[0],28,28,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "553590eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "075326fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "887ff737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize inputs from 0-255 to 0-1\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8437e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode output\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a118ead8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fee15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the number of output target classes\n",
    "num_classes=y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "905710fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1effa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a convolutional model with one convolutional layer and one pooling layer\n",
    "def convolutional_model():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(16, (5,5), strides=(1,1), activation=\"relu\", input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(100,activation=\"relu\"))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2911cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=convolutional_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ed85ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 13s - loss: 0.2811 - accuracy: 0.9203 - val_loss: 0.1027 - val_accuracy: 0.9688\n",
      "Epoch 2/10\n",
      "300/300 - 12s - loss: 0.0833 - accuracy: 0.9751 - val_loss: 0.0598 - val_accuracy: 0.9808\n",
      "Epoch 3/10\n",
      "300/300 - 12s - loss: 0.0571 - accuracy: 0.9829 - val_loss: 0.0506 - val_accuracy: 0.9827\n",
      "Epoch 4/10\n",
      "300/300 - 12s - loss: 0.0433 - accuracy: 0.9874 - val_loss: 0.0449 - val_accuracy: 0.9840\n",
      "Epoch 5/10\n",
      "300/300 - 12s - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.0408 - val_accuracy: 0.9862\n",
      "Epoch 6/10\n",
      "300/300 - 12s - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0389 - val_accuracy: 0.9876\n",
      "Epoch 7/10\n",
      "300/300 - 12s - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.0374 - val_accuracy: 0.9876\n",
      "Epoch 8/10\n",
      "300/300 - 12s - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0394 - val_accuracy: 0.9867\n",
      "Epoch 9/10\n",
      "300/300 - 12s - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0418 - val_accuracy: 0.9872\n",
      "Epoch 10/10\n",
      "300/300 - 12s - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.0377 - val_accuracy: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23d0b5faa30>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f9f751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=model.evaluate(X_test,y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0aa5f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a9096b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "error=1-scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c53d6499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9868999719619751 \n",
      " error:0.013100028038024902\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:{} \\n error:{}\".format(accuracy,error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa7e36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a cnn model with two sets of convolutional and pooling layers and one deep connected neural network \n",
    "def convolutional_model2():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(16, (5,5), strides=(1,1), activation=\"relu\", input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Conv2D(8, (2,2), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(100,activation=\"relu\"))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99c36b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=convolutional_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4f6e5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 14s - loss: 0.4663 - accuracy: 0.8692 - val_loss: 0.1358 - val_accuracy: 0.9596\n",
      "Epoch 2/10\n",
      "300/300 - 14s - loss: 0.1141 - accuracy: 0.9664 - val_loss: 0.0753 - val_accuracy: 0.9771\n",
      "Epoch 3/10\n",
      "300/300 - 14s - loss: 0.0796 - accuracy: 0.9757 - val_loss: 0.0688 - val_accuracy: 0.9790\n",
      "Epoch 4/10\n",
      "300/300 - 14s - loss: 0.0645 - accuracy: 0.9807 - val_loss: 0.0574 - val_accuracy: 0.9811\n",
      "Epoch 5/10\n",
      "300/300 - 14s - loss: 0.0556 - accuracy: 0.9827 - val_loss: 0.0446 - val_accuracy: 0.9855\n",
      "Epoch 6/10\n",
      "300/300 - 14s - loss: 0.0487 - accuracy: 0.9850 - val_loss: 0.0505 - val_accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "300/300 - 14s - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.0382 - val_accuracy: 0.9873\n",
      "Epoch 8/10\n",
      "300/300 - 14s - loss: 0.0400 - accuracy: 0.9878 - val_loss: 0.0373 - val_accuracy: 0.9873\n",
      "Epoch 9/10\n",
      "300/300 - 14s - loss: 0.0356 - accuracy: 0.9889 - val_loss: 0.0354 - val_accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "300/300 - 14s - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.0365 - val_accuracy: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23d001389a0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef686019",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2=model2.evaluate(X_test,y_test, verbose=0)\n",
    "accuracy2=scores2[1]\n",
    "error2=1-accuracy2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f069a0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9873999953269958 \n",
      " error:0.01260000467300415 for model2\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:{} \\n error:{} for model2\".format(accuracy2,error2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "68fe092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the predicted target of X_test using model with one sets of convolutional and pooling layers (first model)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50f07712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.66067920e-09, 6.05648225e-08, 6.36962682e-07, ...,\n",
       "        9.99987721e-01, 2.89264914e-08, 7.17658850e-06],\n",
       "       [2.75090284e-10, 3.93444495e-08, 1.00000000e+00, ...,\n",
       "        1.42296710e-13, 1.23853749e-09, 4.07777670e-15],\n",
       "       [3.36179210e-06, 9.99866962e-01, 7.17448347e-06, ...,\n",
       "        5.13965051e-06, 1.11367081e-04, 1.15241665e-08],\n",
       "       ...,\n",
       "       [6.86953139e-14, 4.26957580e-09, 5.52796529e-15, ...,\n",
       "        1.38682910e-09, 1.63601204e-08, 2.08169944e-08],\n",
       "       [5.50900055e-11, 2.75447655e-12, 2.78245222e-12, ...,\n",
       "        7.20937199e-12, 3.41662781e-06, 7.45813513e-13],\n",
       "       [9.11587819e-12, 4.32308887e-15, 1.00321015e-10, ...,\n",
       "        3.35181210e-19, 3.31974781e-10, 2.09351774e-15]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4233385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aca66a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_decimal=np.argmax(y_pred,axis=1)\n",
    "y_test_decimal=np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8e7bda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "709adb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_predictions=(y_pred_decimal!=y_test_decimal).sum()\n",
    "incorrect_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b61df7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 282,  321,  340,  445,  448,  449,  582,  619,  659,  684,  720,\n",
       "        740,  883,  938,  947, 1014, 1039, 1112, 1156, 1202, 1226, 1232,\n",
       "       1242, 1247, 1260, 1319, 1326, 1393, 1500, 1522, 1527, 1530, 1553,\n",
       "       1709, 1717, 1790, 1878, 1901, 1941, 2024, 2035, 2070, 2098, 2118,\n",
       "       2130, 2135, 2185, 2272, 2280, 2326, 2369, 2387, 2406, 2414, 2462,\n",
       "       2597, 2607, 2654, 2720, 2760, 2896, 2921, 2939, 2995, 3030, 3060,\n",
       "       3172, 3384, 3422, 3503, 3520, 3558, 3601, 3604, 3662, 3727, 3796,\n",
       "       3808, 3853, 3985, 4176, 4199, 4238, 4248, 4256, 4289, 4369, 4497,\n",
       "       4507, 4578, 4639, 4740, 4761, 4807, 4814, 4823, 4838, 4860, 4956,\n",
       "       4966, 5246, 5331, 5887, 5937, 5955, 5973, 5997, 6011, 6023, 6091,\n",
       "       6532, 6571, 6576, 6597, 6625, 6651, 8094, 8246, 8408, 8527, 9009,\n",
       "       9015, 9024, 9540, 9587, 9634, 9664, 9679, 9729, 9770, 9792],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_incorrect_pred=np.where(y_pred_decimal!=y_test_decimal)[0]\n",
    "pos_incorrect_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f41497d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d389380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.reshape(-1,X_test.shape[1],X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67542d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e96f3bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23d01804ee0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[pos_incorrect_pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10687480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[pos_incorrect_pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05185b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_decimal[pos_incorrect_pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a29dbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_decimal[pos_incorrect_pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17fe505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"convolutional_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e6f5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"convolutional_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9adcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd6587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
